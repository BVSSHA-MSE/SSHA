# [Coherence] - Outcome Fluency Through Mapping

**Year:** 2025  
**Level:** Team  
**Theme:** Coherence

## Context & Tension
- BVSSH automation is strong, but discovery is manual and cognitively heavy, yielding shallow or solution-first outcomes.
- We are still validating "high quality" BVSSH outcomes; constraint clarity and signals are inconsistent, causing rework.
- A lightweight, time-boxed outcome mapping step before facilitation may raise quality, but must be low-friction to gain adoption.

## Desired Outcome (BVSSH)
- Better: Outcomes consistently name the primary constraint, include 3–5 meaningful signals, and observable behaviors; quality score trends ≥4.0/5.
- Value: More proposals start outcome-first; outcome rework trends down (~30% reduction).
- Sooner: Outcome formation cycle time trends to p50 ≤12 minutes, p90 ≤20 minutes across sessions.
- Safer: Solution-first proposals trend <10%; ≥90% outcomes name a primary constraint.
- Happier: Self-reported cognitive load trends down (~20% via weekly check-ins).

## Outcome Hypothesis
If we integrate a 12-minute outcome mapping scaffold (with a simple quality rubric) before BVSSH facilitation, then outcome-first will become habitual and quality will improve (constraint clarity + signals + behaviors), because reduced cognitive load and clear guidance make discovery faster, repeatable, and aligned to BVSSH and flow metrics.

## Expected Behavioral Change
- Before: We draft activity lists or jump to solutions; outcomes lack clear constraints and signals.
- After: We start with mapping scaffold; proposals begin with a constraint-aligned target outcome including ≥3 BVSSH signals and observable behaviors.
- Stops/Starts: Stop solution-first proposals; start outcome mapping (≤12 minutes) before facilitation.

## Signals & Measures
- Leading (1–3):
  - Mapping cycle time p50/p90 (weekly trend toward p50 ≤12m, p90 ≤20m).
  - Adoption rate: % proposals starting with mapped outcomes (trend toward ≥85%).
  - Draft quality checklist: named constraint + ≥3 BVSSH signals (weekly trend).
- Lagging (1–3):
  - Outcome quality score (rubric 1–5): average trends ≥4.0/5.
  - Outcome rework rate: trend decreases by ~30% over pilot.

## Constraints & Guardrails
- Constraints: Discovery cognitive load; unclear quality signals; end-of-year bandwidth; adoption skepticism.
- Guardrails:
  - Optimize habit and speed over exhaustive documentation.
  - Require named primary constraint; cap signals at 3–5; avoid vanity metrics.
  - Time-box mapping to ≤12 minutes; automation is assistive, not prescriptive.

## Review & Learning Cadence
- Weekly review (Facilitator, Automation Lead, Advocacy Lead): inspect cycle time, adoption, quality score trends; decide continue/adjust/stop.
- A/B pilot (4 weeks): compare Mapping→Facilitation vs. direct facilitation; evaluate signal alignment and rework trends.
- Decision enabled: Roll-in to default automation or revise scaffold/rubric based on learning.

## Cross-Level Coherence
### Parent Links
- Enables Program outcome: [bvssh/2025/program/easier-to-drive-change-with-bvssh-outcomes.md](bvssh/2025/program/easier-to-drive-change-with-bvssh-outcomes.md) — Easier to Drive Change with BVSSH Outcomes
- Supports Portfolio outcome: [bvssh/2025/portfolio/ssh-advocacy-embedded-portfolio-wide.md](bvssh/2025/portfolio/ssh-advocacy-embedded-portfolio-wide.md) — SSH Advocacy Embedded Portfolio-Wide

### Signal Cascade
- Leading indicators (mapping cycle time trend, adoption rate, checklist quality) influence Program lagging indicators (formation time trend, adoption/fluency, outcome quality).
- Program indicators roll up to Portfolio governance signals (share of items linked to outcomes, reduction of activity-only proposals, faster decision rhythm).

### Review Sync
- Weekly reviews feed Program reviews (bi-weekly or monthly) and summarize into Portfolio quarterly reviews to propagate learning and decisions upward.
## Reflection (Post-Outcome)
Capture surprises, validated/invalidated assumptions (e.g., friction vs. quality trade-off), and changes for next cycle (rubric tweaks, prompts, automation nudge timing).

### Traceability
- Source session notes: [kb/outcome-mapping/sessions/20251220-141500-bvssh-fluency-via-outcome-mapping.md](kb/outcome-mapping/sessions/20251220-141500-bvssh-fluency-via-outcome-mapping.md)

## Outcome Statement (SMART)
By the end of a 6-week pilot, make outcome-first habitual by adding a 12-minute outcome mapping scaffold integrated with automation, so that ≥85% our proposals begin with a constraint-aligned target outcome including ≥3 BVSSH signals; mapping cycle time p50 ≤12 minutes (p90 ≤20); outcome quality score ≥4.0/5; with trends monitored weekly and used for decisions.
